# 规则引擎与大模型推理技术文档

## 1. 规则引擎架构

规则引擎是本系统的核心组件之一，用于基于已知关系推导新的地名关系。规则引擎采用基于JSON的规则定义方式，每条规则包含条件(condition)和推理结果(inference)两部分。

规则引擎的主要特点：
- 基于关系类型和具体关系匹配触发条件
- 支持方向性推理，可根据需要保持或反转关系方向
- 支持复合规则，可基于多个基础关系推导出新关系
- 规则带有优先级，处理潜在的规则冲突

规则的基本结构示例：

```json
{
  "rule_id": "rule_001",
  "name": "演变类基础推理规则",
  "condition": {
    "relation_type": "演变类"
  },
  "inference": {
    "relation": "源自于",
    "direction": "reverse"
  },
  "description": "如果A--[演变类关系]-->B，则B源自于A"
}
```

**规则描述的自然语言解释**：

上述规则"如果A--[演变类关系]-->B，则B源自于A"的自然语言表述为：

当我们发现一个地名A演变为另一个地名B时（例如A更名为B，A升格为B，A合并为B等），我们可以推断新的地名B是源自于旧的地名A的。这反映了地名演变的历史脉络，建立了新地名与其历史前身之间的溯源关系。

例如，如果知识图谱中存在"平江府演变为苏州府"这一关系，应用此规则后，系统会推断出"苏州府源自于平江府"这一新关系。这种推理使系统能够回答"苏州府的历史前身是什么"之类的问题。

在系统中，规则主要分为三大类：

### 1.1 演变类规则

演变类规则用于处理地名历史演变关系，描述一个地名如何随着时间推移而变化。这类规则是理解地名历史沿革的基础。

**典型关系包括**：
- **更名**：行政区划名称变更，如"平江路"更名为"苏州路"
- **升格**：行政级别提升，如"县"升格为"市"
- **降格**：行政级别降低，如"郡"降格为"县"
- **合并**：多个行政区合并为一个，如多个县合并为一个市
- **析置**：从一个行政区中分出新的行政区
- **设立**：新设立一个行政区
- **废止**：取消一个行政区

**演变类规则示例**：
```json
{
  "rule_id": "rule_003",
  "name": "更名推理规则",
  "condition": {
    "relation": "更名"
  },
  "inference": {
    "relation": "改称自",
    "direction": "reverse"
  },
  "description": "如果A--[更名]-->B，则B改称自A"
}
```

上述"更名推理规则"的自然语言解释为：当地名A更名为地名B时，我们可以推断出地名B是由地名A改称而来的。例如，如果知识图谱中记录了"平江路更名为苏州路"，通过此规则可以推断出"苏州路改称自平江路"，这种表述更加符合我们描述地名沿革时的自然表达方式。

**应用场景**：当用户询问"苏州路的历史名称是什么"时，系统可以通过演变类规则推断出"苏州路改称自平江路"。

### 1.2 所属类规则

所属类规则处理行政区划的隶属关系，描述不同级别行政区之间的从属关系。这类规则是理解行政区划层级结构的基础。

**典型关系包括**：
- **隶属**：下级行政区隶属于上级行政区，如"县"隶属于"省"
- **辖域**：上级行政区辖管下级行政区
- **下辖**：表示上级行政区下辖某个区域
- **管辖**：表示对某区域有行政管理权

**所属类规则示例**：
```json
{
  "rule_id": "rule_012",
  "name": "所属类基础推理规则",
  "condition": {
    "relation_type": "下辖"
  },
  "inference": {
    "relation": "隶属",
    "direction": "reverse"
  },
  "description": "如果A--下辖-->B，则B下辖A"
}
```

**应用场景**：当用户询问"太仓县属于哪个行政区"时，系统可以通过所属类规则推断出"太仓县隶属于苏州府"。

### 1.3 复合规则

复合规则基于多个基础关系推导出新的复杂关系，能够处理需要多步推理的情况。这类规则扩展了系统的推理能力，使其能处理更复杂的查询。

**典型模式**：
- **传递性规则**：如果A与B有关系，B与C有关系，则A与C也有某种关系
- **组合性规则**：基于多种不同类型关系的组合推导出新关系
- **时序性规则**：考虑时间顺序的多步演变推理

**复合规则示例**：
```json
{
  "rule_id": "rule_017",
  "name": "管辖链复合规则",
  "condition": {
    "relation": "下辖",
    "composite": true,
    "path_length": 2
  },
  "inference": {
    "relation": "间接管辖",
    "direction": "forward",
    "transitive": true
  },
  "description": "如果A下辖B且B下辖C，则A间接管辖C（C被A间接管辖）"
}
```

**应用场景**：当用户询问"明朝时期杭州府与南直隶的关系"时，系统可以通过复合规则推断出"南直隶间接管辖杭州府"（如果存在"南直隶下辖浙江省"和"浙江省下辖杭州府"这两个基础关系）。

这三类规则相互配合，共同构成了系统的推理基础。演变类规则处理时间维度上的地名变迁，所属类规则处理空间维度上的行政区划层级关系，而复合规则则通过组合基础关系实现更复杂的多步推理，使系统能够回答涉及地名历史沿革和行政区划变迁的复杂问题。

## 2. 规则加载与索引构建

规则加载与索引构建是规则引擎初始化的关键步骤，主要包括从JSON文件加载规则定义，并构建索引以提高规则匹配效率。系统的规则存储在`rules/rule_base.json`文件中。

### 2.1 规则加载

规则引擎通过`RuleLLMIntegration`类实现，在初始化时加载规则并构建索引：

```python
def __init__(self, rule_file_path: str = 'rules/rule_base.json', 
             model_name: str = "deepseek-r1:7b",
             max_depth: int = 30):
    """
    初始化推理引擎
    
    Args:
        rule_file_path: 规则库文件路径
        model_name: 使用的大模型名称
        max_depth: 图谱搜索的最大深度
    """
    self.model_name = model_name
    self.max_depth = max_depth
    
    # 加载规则库
    self.rules = self._load_rules(rule_file_path)
    self.rule_id_map = {rule['rule_id']: rule for rule in self.rules}
    
    # 规则分类缓存，用于快速查找
    self._build_rule_indices()
    
    print(f"规则与大模型推理引擎已初始化, 使用模型: {model_name}, 规则数量: {len(self.rules)}")
```

规则从指定的JSON文件加载：

```python
def _load_rules(self, rule_file_path: str) -> List[Dict]:
    """加载规则库"""
    try:
        with open(rule_file_path, 'r', encoding='utf-8') as f:
            rules = json.load(f)
        print(f"成功加载规则库，共 {len(rules)} 条规则")
        return rules
    except Exception as e:
        print(f"加载规则库失败: {str(e)}")
        return []
```

### 2.2 索引构建

为提高规则匹配效率，系统构建了三种索引：按关系类型、按具体关系和复合规则索引：

```python
def _build_rule_indices(self):
    """构建规则索引，方便后续查找"""
    # 按关系类型索引
    self.relation_type_rules = {}
    # 按具体关系索引
    self.relation_rules = {}
    # 按复合规则索引
    self.composite_rules = []
    
    for rule in self.rules:
        # 检查是否是复合规则
        if 'composite' in rule.get('condition', {}) and rule['condition']['composite']:
            self.composite_rules.append(rule)
            continue
        
        # 按关系类型索引
        if 'relation_type' in rule.get('condition', {}):
            rel_type = rule['condition']['relation_type']
            if rel_type not in self.relation_type_rules:
                self.relation_type_rules[rel_type] = []
            self.relation_type_rules[rel_type].append(rule)
        
        # 按具体关系索引
        if 'relation' in rule.get('condition', {}):
            relation = rule['condition']['relation']
            if relation not in self.relation_rules:
                self.relation_rules[relation] = []
            self.relation_rules[relation].append(rule)
    
    print(f"规则索引构建完成: {len(self.relation_type_rules)} 种关系类型, "
          f"{len(self.relation_rules)} 种具体关系, {len(self.composite_rules)} 条复合规则")
```

这种索引结构使得系统可以根据关系类型或具体关系快速查找适用的规则，大大提高了规则匹配效率。在推理过程中，系统会根据需要查找适用规则：

```python
def _find_applicable_rules(self, relation_type: Optional[str] = None, 
                          relation: Optional[str] = None) -> List[Dict]:
    """
    查找适用于给定关系类型和关系的规则
    
    Args:
        relation_type: 关系类型
        relation: 具体关系
        
    Returns:
        适用规则列表
    """
    applicable_rules = []
    
    # 按关系类型查找
    if relation_type and relation_type in self.relation_type_rules:
        applicable_rules.extend(self.relation_type_rules[relation_type])
    
    # 按具体关系查找
    if relation and relation in self.relation_rules:
        applicable_rules.extend(self.relation_rules[relation])
    
    # 按优先级排序
    if applicable_rules:
        applicable_rules.sort(key=lambda x: x.get('priority', 0), reverse=True)
    
    return applicable_rules
```

## 3. 规则应用与推理

规则应用是将定义好的规则应用于已知关系，以推导出新关系的过程。这个过程是知识图谱增强的核心机制。

### 3.1 规则匹配与筛选

系统首先需要匹配关系，找出适用的规则：

```python
def _find_applicable_rules(self, relation_type: Optional[str] = None, 
                          relation: Optional[str] = None) -> List[Dict]:
    """
    查找适用于给定关系类型和关系的规则
    """
    applicable_rules = []
    
    # 按关系类型查找
    if relation_type and relation_type in self.relation_type_rules:
        applicable_rules.extend(self.relation_type_rules[relation_type])
    
    # 按具体关系查找
    if relation and relation in self.relation_rules:
        applicable_rules.extend(self.relation_rules[relation])
    
    # 按优先级排序
    if applicable_rules:
        applicable_rules.sort(key=lambda x: x.get('priority', 0), reverse=True)
    
    return applicable_rules
```

### 3.2 规则推理执行

找到适用规则后，系统会应用规则生成新的推理关系：

```python
def apply_inference_rules(self, relationships: List[Dict]) -> List[Dict]:
    """应用推理规则，生成新的关系"""
    inferred_relationships = []
    
    for rel in relationships:
        # 跳过已经是推理关系的条目，避免重复推理
        if rel.get('properties', {}).get('inferred', False):
            continue
        
        # 获取关系类型和具体关系
        relation_type = rel.get('properties', {}).get('relation_type', '')
        relation = rel.get('properties', {}).get('relation', '')
        if not relation:
            relation = rel.get('relation', '')
            
        # 分类规则：大类规则和细分规则
        big_category_rules = []  # 大类规则（演变类、所属类）
        specific_rules = []      # 细分规则
        
        # 获取可应用的规则并分类
        for rule in self.rules:
            condition = rule.get('condition', {})
            # 跳过复合规则
            if condition.get('composite', False):
                continue
                
            rule_relation_type = condition.get('relation_type', '')
            rule_relation = condition.get('relation', '')
            
            # 大类规则匹配
            if rule_relation_type in ["演变类", "所属类"] and rule_relation_type == relation_type:
                if not rule_relation or rule_relation == relation:
                    big_category_rules.append(rule)
            
            # 细分规则匹配
            elif rule_relation:
                if rule_relation == relation:
                    # 如果规则有relation_type且与关系不匹配，则跳过
                    if rule_relation_type and rule_relation_type != relation_type:
                        continue
                    specific_rules.append(rule)
        
        # 合并大类规则和细分规则，确保至少应用大类规则
        applicable_rules = big_category_rules + specific_rules
        
        # 应用规则
        for rule in applicable_rules:
            # 获取规则的推理部分
            inference = rule.get('inference', {})
            inferred_relation = inference.get('relation', '')
            direction = inference.get('direction', 'forward')
            
            # 创建新关系
            inferred_rel = {
                # 关系结构定义
                'source': {...},
                'target': {...},
                'relation': inferred_relation,
                'properties': {
                    'inferred': True,
                    'rule_id': rule['rule_id'],
                    'rule_name': rule.get('name', ''),
                    'derived_from': relation
                }
            }
            
            # 处理关系方向
            if direction == "reverse":
                inferred_rel['source'], inferred_rel['target'] = inferred_rel['target'], inferred_rel['source']
            
            inferred_relationships.append(inferred_rel)
    
    return inferred_relationships
```

### 3.3 方向处理

系统对于不同类型的关系有特殊的方向处理逻辑，特别是对于演变类和所属类关系：

```python
# 处理方向 - 修复演变类关系方向问题
if relation_type == "演变类":
    # 对于演变类关系，数据已在导入时做过方向反转
    # 因此关系方向是：被演变实体 -> 演变而来的实体
    if direction == "forward":
        # 对于forward规则，保持原有方向
        pass
    else:
        # 对于reverse规则，反转方向
        inferred_rel['source'], inferred_rel['target'] = inferred_rel['target'], inferred_rel['source']
elif relation_type == "所属类":
    # 所属类中，实际数据存储是 A--所属类关系-->B，
    # 表示 A 隶属于 B，B 下辖 A
    if direction == "reverse":
        # 反转关系方向
        inferred_rel['source'], inferred_rel['target'] = inferred_rel['target'], inferred_rel['source']
else:
    # 处理其他类型关系
    if direction == "reverse":
        inferred_rel['source'], inferred_rel['target'] = inferred_rel['target'], inferred_rel['source']
```

## 4. 大模型集成

系统集成了大语言模型以增强推理能力，主要使用Ollama框架与开源模型进行交互。当前默认使用的是deepseek-r1:7b模型，但系统设计支持灵活切换不同的模型。

### 4.1 模型初始化

模型在系统初始化时配置，可通过构造函数参数指定使用的模型：

```python
def __init__(self, rule_file_path: str = 'rules/rule_base.json', 
             model_name: str = "deepseek-r1:7b",
             max_depth: int = 30):
    """
    初始化推理引擎
    
    Args:
        rule_file_path: 规则库文件路径
        model_name: 使用的大模型名称
        max_depth: 图谱搜索的最大深度
    """
    self.model_name = model_name
    self.max_depth = max_depth
    
    # 加载规则库
    self.rules = self._load_rules(rule_file_path)
    self.rule_id_map = {rule['rule_id']: rule for rule in self.rules}
    
    # 规则分类缓存，用于快速查找
    self._build_rule_indices()
    
    print(f"规则与大模型推理引擎已初始化, 使用模型: {model_name}, 规则数量: {len(self.rules)}")
```

在后端应用启动时，会初始化实体提取器和规则引擎，默认使用deepseek-r1:7b模型：

```python
@app.before_request
def initialize_entity_extractor():
    # 添加对entity_extract的支持
    if not hasattr(g, 'entity_extractor'):
        try:
            from entity_extract.extractor import Extractor
            g.entity_extractor = Extractor()
            print("实体提取器已初始化")
        except Exception as e:
            print(f"初始化实体提取器失败: {str(e)}")
            
    # 添加对规则推理模块的支持
    if not hasattr(g, 'rule_llm_integration'):
        try:
            from inference.rule_llm_integration import RuleLLMIntegration
            g.rule_llm_integration = RuleLLMIntegration(
                rule_file_path='rules/rule_base.json',
                model_name='deepseek-r1:7b',
                max_depth=30
            )
            print("规则推理模块已初始化")
        except Exception as e:
            print(f"初始化规则推理模块失败: {str(e)}")
```

### 4.2 大模型实体抽取

系统使用大语言模型进行地名实体抽取，通过专门的`Extractor`类实现：

```python
class Extractor:
    """
    基于大模型的地名实体提取器
    使用Ollama提供的大模型能力和deepseek-r1模型提取所有地名实体
    """
    
    def __init__(self, model_name="deepseek-r1:7b"):
        """初始化提取器"""
        self.model_name = model_name
        print(f"已初始化大模型地名实体提取器，使用模型: {model_name}")
```

#### 4.2.1 实体抽取流程

实体抽取流程主要包括以下步骤，并进行了详细的性能记录和错误处理：

1. **提示词构建**：构建专门的提示词引导模型识别地名实体
2. **模型调用**：使用Ollama框架调用大模型进行实体识别
3. **结果解析**：从模型输出中解析出地名实体列表
4. **后处理**：对抽取的实体进行去重、过滤和排序

核心抽取方法实现：

```python
def extract_entities(self, text):
    """
    从文本中提取所有地名实体（包括现代地名和历史地名）
    
    Args:
        text: 输入文本
        
    Returns:
        list: 提取的地名实体列表
    """
    if not text or len(text.strip()) == 0:
        print("输入文本为空，无法提取实体")
        return []
    
    # 记录文本的开头部分作为示例
    text_preview = text[:100] + "..." if len(text) > 100 else text
    print(f"准备提取文本中的地名实体，文本长度: {len(text)} 字符，文本开头: '{text_preview}'")
    
    # 构建提示词
    prompt = self._build_prompt(text)
    
    try:
        # 记录总体开始时间
        total_start_time = time.time()
        
        # 记录模型调用开始时间
        model_start_time = time.time()
        print(f"调用 {self.model_name} 模型进行地名实体提取...")
        # 调用大模型进行实体提取
        response = ollama.chat(
            model=self.model_name,
            messages=[
                {
                    "role": "system",
                    "content": "你是一个专业的地名识别专家。你的任务是从文本中准确识别出所有地名实体，"
                               "包括现代和历史地名、国内和国外地名、行政区划、自然地理实体等。请返回所有可能的地名，"
                               "不要遗漏任何地名。返回的地名实体应当是具体的地点名称，而不是泛指的地理概念。"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            stream=False
        )
        
        # 记录模型调用耗时
        model_time = time.time() - model_start_time
        print(f"模型响应成功，耗时: {model_time:.2f}秒，"
              f"响应长度: {len(response['message']['content'])} 字符，开始解析实体...")
        
        # 从响应中解析实体
        extracted_entities = self._parse_entities_from_response(response['message']['content'])
        
        # 过滤和排序结果
        result = self._post_process_entities(extracted_entities)
        
        # 计算总体耗时
        total_time = time.time() - total_start_time
        
        print(f"地名实体提取完成，总耗时: {total_time:.2f}秒")
        
        return result
        
    except Exception as e:
        error_type = type(e).__name__
        error_details = str(e)
        print(f"大模型实体提取失败: {error_type} - {error_details}")
        import traceback
        print(f"错误追踪: {traceback.format_exc()}")
        # 如果大模型调用失败，返回空列表
        return []
```

#### 4.2.2 提示词设计

系统使用专门设计的提示词引导大模型抽取地名实体，提示词设计兼顾了提取精度和格式规范：

```python
def _build_prompt(self, text):
    """构建提示词，引导模型提取所有地名实体"""
    prompt = f"""请从以下文本中识别并提取所有地名实体:

{text}

要求:
1. 提取所有地名实体，包括现代地名和历史地名
2. 包括城市、省份、国家、地区、山川、河流等所有地理实体
3. 包括现代行政区划（如市、区、县）和古代行政区划（如府、州、郡、县、路）
4. 尽可能详尽地提取所有地名，不要遗漏
5. 专注于识别"地名"，不要提取人名、组织名称等其他实体类型

请以JSON格式返回提取结果，格式如下:
```json
{{
  "entities": ["地名1", "地名2", "地名3", ...]
}}
```

只返回JSON结果，不要有其他解释。"""
    
    return prompt
```

#### 4.2.3 实体解析与后处理

系统采用多种解析策略，以应对不同格式的模型输出，并增加了详细的日志记录：

```python
def _parse_entities_from_response(self, response_text):
    """从模型响应中解析实体列表"""
    try:
        # 尝试从响应中提取JSON部分
        json_start = response_text.find('{')
        json_end = response_text.rfind('}') + 1
        
        if json_start >= 0 and json_end > json_start:
            json_str = response_text[json_start:json_end]
            try:
            data = json.loads(json_str)
            if 'entities' in data and isinstance(data['entities'], list):
                    print(f"成功通过JSON格式解析，找到实体数量: {len(data['entities'])}")
                return data['entities']
            except Exception as json_err:
                print(f"JSON解析失败: {str(json_err)}")
        
        # 如果没找到JSON或解析失败，尝试其他解析方法
        # 查找列表形式
        if '[' in response_text and ']' in response_text:
            list_start = response_text.find('[')
            list_end = response_text.rfind(']') + 1
            if list_start >= 0 and list_end > list_start:
                list_str = response_text[list_start:list_end]
                try:
                    entities = json.loads(list_str)
                    if isinstance(entities, list):
                        print(f"通过列表格式解析，找到实体数量: {len(entities)}")
                        return entities
                except Exception as list_err:
                    print(f"列表解析失败: {str(list_err)}")
        
        print("标准解析失败，尝试按行分割进行解析")
        # 回退方案：按行分割并清理
        lines = response_text.split('\n')
        entities = []
        for line in lines:
            line = line.strip()
            # 移除行首的数字、点、破折号等前缀
            line = line.lstrip('0123456789.- "\'')
            line = line.strip()
            if line and len(line) >= 2:
                entities.append(line)
        
        print(f"通过行分割解析，找到实体数量: {len(entities)}")
        return entities
        
    except Exception as e:
        print(f"解析模型响应失败: {str(e)}")
        print(f"原始响应: {response_text}")
        return []
```

后处理部分负责过滤和优化抽取的实体，确保实体质量：

```python
def _post_process_entities(self, entities):
    """对提取的实体进行后处理，包括去重、过滤和排序"""
    if not entities:
        return []
    
    # 去重
    unique_entities = list(set(entities))
    
    # 过滤明显不是地名的实体和太短的实体
    filtered_entities = [entity for entity in unique_entities 
                        if len(entity) >= 2 and not self._should_filter(entity)]
    
    # 按长度排序（优先考虑较长的地名，通常更具体）
    filtered_entities.sort(key=len, reverse=True)
    
    # 记录过滤统计
    if len(unique_entities) > 0:
        filter_rate = (len(unique_entities) - len(filtered_entities)) / len(unique_entities)
        print(f"实体过滤: 原始 {len(unique_entities)} 个 -> 过滤后 {len(filtered_entities)} 个, 过滤率: {filter_rate:.2%}")
    
    return filtered_entities
```

#### 4.2.4 系统集成

在`app.py`中，系统在应用启动时初始化实体提取器，并在API端点中处理用户查询：

```python
@app.route('/api/ai/inference', methods=['POST', 'GET'])
def ai_inference():
    """
    人工智能推理接口
    使用规则引擎和大模型进行推理
    """
    try:
        # 获取请求数据
        if request.method == 'POST':
            data = request.json
            user_question = data.get('question', '')
        else:  # GET方法
            user_question = request.args.get('question', '')
        
        if not user_question:
            return jsonify({
                'code': 400,
                'message': '请提供问题内容',
                'data': None
            })
            
        # 记录请求信息
        print(f"收到AI推理请求: {user_question}")
        
        # 调用规则和模型进行推理
result = g.rule_llm_integration.process_question(
    question=user_question,
    entity_extractor=g.entity_extractor,
    neo4j_db=neo4j_db_handle
)
        
        # 返回结果
        return jsonify({
            'code': 200,
            'message': 'success',
            'data': result
        })
        
    except Exception as e:
        print(f"AI推理处理错误: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'code': 500,
            'message': f'服务器处理错误: {str(e)}',
            'data': None
        })
```

### 4.3 模型回答生成

系统使用Ollama框架调用大模型进行推理，并设置了低温度参数以提高回答的确定性：

```python
def generate_response_with_llm(self, 
                              question: str,
                              entities: List[str],
                              entity_info: List[Dict],
                              relationships: List[Dict],
                              paths: List[Dict]) -> str:
    """使用大模型生成回答"""
    # 构建提示词
    prompt = self._build_inference_prompt(
        question=question,
        entities=entities,
        entity_info=entity_info,
        relationships=relationships,
        paths=paths
    )
    
    try:
        # 调用大模型生成回答
        response = ollama.chat(
            model=self.model_name,
            messages=[
                {
                    "role": "system", 
                    "content": """你是一个专业的中国历史地名专家，精通地名沿革、行政区划变迁和地理位置关系。..."""
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            stream=False,
            options={"temperature": 0.1}  # 添加低温度参数，提高回答确定性
        )
        
        # 返回模型生成的回答
        return response['message']['content']
        
    except Exception as e:
        print(f"模型调用失败: {str(e)}")
        return f"抱歉，在处理您的问题时遇到了技术问题。错误信息: {str(e)}"
```

## 5. 提示词工程与生成

提示词工程是大模型调用的关键环节，好的提示词设计可以极大地提高模型回答的准确性和相关性。

### 5.1 提示词生成

系统根据问题、实体信息、关系和路径构建结构化的提示词：

```python
def _build_inference_prompt(self, 
                           question: str,
                           entities: List[str],
                           entity_info: List[Dict],
                           relationships: List[Dict],
                           paths: List[Dict]) -> str:
    """构建推理提示词"""
    
    # 格式化实体信息为文本
    entity_info_text = ""
    for i, info in enumerate(entity_info):
        if info:
            properties = info.get('properties', {})
            props_text = ", ".join([f"{k}: {v}" for k, v in properties.items() if k != 'name'])
            entity_info_text += f"{i+1}. {info.get('name', '')} (类型: {info.get('type', '未知')})"
            if props_text:
                entity_info_text += f", 属性: {props_text}"
            entity_info_text += "\n"
    
    # 分离原始关系和推理关系
    original_relationships = []
    inferred_relationships = []
    
    for rel in relationships:
        if rel.get('properties', {}).get('inferred', False) or rel.get('inferred', False):
            inferred_relationships.append(rel)
        else:
            original_relationships.append(rel)
    
    # 格式化关系信息为文本
    relationships_text = "原始关系(直接来自知识图谱):\n"
    for i, rel in enumerate(original_relationships):
        source = rel.get('source', {}).get('name', '')
        target = rel.get('target', {}).get('name', '')
        relation = rel.get('relation', '')
        relationships_text += f"{i+1}. {source} --[{relation}]--> {target}\n"
    
    relationships_text += "\n推理关系(通过规则推理生成):\n"
    for i, rel in enumerate(inferred_relationships):
        source = rel.get('source', {}).get('name', '')
        target = rel.get('target', {}).get('name', '')
        relation = rel.get('relation', '')
        relationships_text += f"{i+1}. {source} --[{relation}]--> {target}\n"
    
    # 格式化路径信息
    paths_text = ""
    for i, path_data in enumerate(paths):
        path = path_data.get('path', [])
        if path:
            path_str = path[0].get('name', '')
            for j in range(1, len(path)):
                node = path[j]
                relation = node.get('relation_type', '')
                path_str += f" --[{relation}]--> {node.get('name', '')}"
            paths_text += f"{i+1}. {path_str}\n"
```

### 5.2 提示词模板

系统使用结构化的提示词模板，指导模型进行专业的地名知识解读：

```
prompt = f"""你是一个专业的中国历史地名专家，精通地名沿革、行政区划变迁和地理位置关系。

在分析地名关系时，请注意以下重要规则：
1. 演变类关系表示地名的历史演变，A --[演变类]--> B 意味着"A演变为B"
2. 推理关系是基于原始关系推导出的，应当与原始关系结合分析

请确保你的回答：
- 准确反映地名的历史演变顺序
- 正确解读行政隶属关系
- 清晰区分原始关系和推理关系
- 基于证据推理，如无明确证据，说明这是推测

所有回答必须基于知识图谱提供的事实，不要添加图谱之外的历史信息。

用户问题: {question}

识别到的地名实体: {', '.join(entities) if entities else '无'}

实体详情:
{entity_info_text if entity_info_text else '无可用实体详情'}

实体关系 (注意: A--[演变类]-->B 表示"A演变为B"):
{relationships_text if relationships_text else '无可用实体关系'}

实体之间的路径 (从源实体到目标实体的关系链):
{paths_text if paths_text else '无可用路径信息'}

基于上述地名知识图谱中的信息，请分析并回答用户问题...
"""
```

## 6. 知识图谱查询与处理

系统需要从知识图谱中获取实体信息、关系和路径，以支持后续的规则推理和大模型生成。

### 6.1 实体关系查询

系统通过Neo4j查询实体的出向和入向关系：

```python
def get_entity_relationships(self, entity_id: int, neo4j_db) -> List[Dict]:
    """获取实体的关系"""
    try:
        # 获取出向关系
        query_outgoing = f"""
        MATCH (n)-[r]->(m)
        WHERE ID(n) = {entity_id}
        RETURN n, r, m, 'outgoing' as direction
        """
        
        # 获取入向关系
        query_incoming = f"""
        MATCH (n)<-[r]-(m)
        WHERE ID(n) = {entity_id}
        RETURN n, r, m, 'incoming' as direction
        """
        
        # 合并结果
        results_outgoing = neo4j_db.graph.run(query_outgoing).data()
        results_incoming = neo4j_db.graph.run(query_incoming).data()
        
        relationships = []
        processed_relations = set()  # 用于去重
        
        # 处理所有结果
        for result in results_outgoing + results_incoming:
            # 构建关系数据结构
            source_node = result['n'] if result['direction'] == 'outgoing' else result['m']
            target_node = result['m'] if result['direction'] == 'outgoing' else result['n']
            relation = result['r']
            
            # 创建关系的唯一标识，避免重复
            relation_id = f"{source_node.identity}_{target_node.identity}_{type(relation).__name__}"
            if relation_id in processed_relations:
                continue
            
            processed_relations.add(relation_id)
            
            # 构建关系信息
            rel_info = {
                'source': {
                    'id': source_node.identity,
                    'name': source_node.get('name', ''),
                    'type': list(source_node.labels)[0] if source_node.labels else ''
                },
                'target': {
                    'id': target_node.identity,
                    'name': target_node.get('name', ''),
                    'type': list(target_node.labels)[0] if target_node.labels else ''
                },
                'relation': type(relation).__name__,
                'properties': {k: v for k, v in relation.items()},
                'direction': result['direction']
            }
            relationships.append(rel_info)
        
        return relationships
    except Exception as e:
        print(f"获取实体关系时出错: {str(e)}")
        return []
```

### 6.2 实体路径搜索

系统查找两个实体之间的最短路径：

```python
def search_paths_between_entities(self, entity1_id: int, entity2_id: int, 
                                 neo4j_db, max_depth: Optional[int] = None) -> List[Dict]:
    """搜索两个实体之间的路径"""
    if max_depth is None:
        max_depth = self.max_depth
        
    try:
        # 查询从entity1到entity2的有向路径
        query_forward = f"""
        MATCH path = shortestPath((n)-[*1..{max_depth}]->(m))
        WHERE ID(n) = {entity1_id} AND ID(m) = {entity2_id}
        RETURN path
        LIMIT 5
        """
        
        # 查询从entity2到entity1的有向路径
        query_backward = f"""
        MATCH path = shortestPath((n)-[*1..{max_depth}]->(m))
        WHERE ID(n) = {entity2_id} AND ID(m) = {entity1_id}
        RETURN path
        LIMIT 5
        """
        
        # 合并结果并优先使用正向路径
        results = []
        forward_results = neo4j_db.graph.run(query_forward).data()
        backward_results = neo4j_db.graph.run(query_backward).data()
        
        if forward_results:
            results = forward_results
        elif backward_results:
            results = backward_results
        
        # 处理路径结果
        paths = []
        for result in results:
            path = result.get('path')
            if not path:
                continue
                
            # 提取路径中的节点和关系
            nodes = list(path.nodes)
            rels = list(path.relationships)
            
            # 构建路径数据
            path_data = []
            last_node_name = None
            last_node_id = None
            
            for i, node in enumerate(nodes):
                # 构建节点信息
                node_data = {
                    'name': node['name'],
                    'id': node.identity,
                    'type': list(node.labels)[0] if node.labels else ''
                }
                
                # 添加关系信息
                if i > 0 and i-1 < len(rels):
                    rel = rels[i-1]
                    rel_type = type(rel).__name__
                    
                    if rel.start_node.identity == last_node_id:
                        node_data['relation'] = f"{last_node_name} -{rel_type}-> {node['name']}"
                        node_data['relation_direction'] = 'outgoing'
                    else:
                        node_data['relation'] = f"{last_node_name} <-{rel_type}- {node['name']}"
                        node_data['relation_direction'] = 'incoming'
                    
                    node_data['relation_type'] = rel_type
                    node_data['relation_properties'] = {k: v for k, v in rel.items()}
                
                last_node_name = node['name']
                last_node_id = node.identity
                path_data.append(node_data)
            
            # 添加路径信息
            paths.append({
                'path': path_data,
                'length': len(rels),
                'start_entity': path_data[0]['name'] if path_data else None,
                'end_entity': path_data[-1]['name'] if path_data else None
            })
        
        return paths
            
    except Exception as e:
        print(f"搜索路径时出错: {str(e)}")
        return []
```

## 7. 综合推理流程

系统的整体推理流程集成了实体提取、知识图谱查询、规则推理和大模型生成等多个环节，前后端通过RESTful API进行通信。

### 7.1 问题处理流程

系统提供了完整的问题处理流程，包括精确的性能统计和详细的日志记录：

```python
def process_question(self, question: str, entity_extractor, neo4j_db) -> Dict:
    """处理用户问题，返回推理结果"""
    start_time = time.time()
    
    try:
        # 1. 从问题中提取实体
        print(f"正在从问题中提取实体: '{question}'")
        entities = entity_extractor.extract_entities(question)
        print(f"提取到 {len(entities)} 个实体: {', '.join(entities)}")
        
        if not entities:
            return {
                'answer': "抱歉，我无法从您的问题中识别出任何地名实体。请尝试提供更具体的地名。",
                'entities': [],
                'kg_data': {'nodes': [], 'lines': []},
                'process_time': time.time() - start_time
            }
        
        # 2. 从知识图谱中查询实体信息
        print("正在从知识图谱查询实体信息...")
        all_entity_info = []
        entity_info_map = {}
        for entity in entities:
            # 实体查询和处理逻辑...
        
        # 3. 获取实体关系
        print("正在获取实体关系...")
        all_relationships = []
        for info in all_entity_info:
            entity_id = info['id']
            relationships = self.get_entity_relationships(entity_id, neo4j_db)
            all_relationships.extend(relationships)
        
        # 4. 搜索实体之间的路径
        print("正在搜索实体间的路径关系...")
        all_paths = []
        if len(all_entity_info) >= 2:
            for i in range(len(all_entity_info)):
                for j in range(i+1, len(all_entity_info)):
                    entity1_id = all_entity_info[i]['id']
                    entity2_id = all_entity_info[j]['id']
                    paths = self.search_paths_between_entities(entity1_id, entity2_id, neo4j_db)
                    all_paths.extend(paths)
        
        # 5. 应用推理规则
        print("正在应用推理规则...")
        start_inference = time.time()
        inferred_relationships = self.apply_inference_rules(all_relationships)
        inference_time = time.time() - start_inference
        print(f"规则推理完成，推导出 {len(inferred_relationships)} 个新关系，耗时: {inference_time:.2f}秒")
        
        original_relationships = all_relationships.copy()
        all_relationships.extend(inferred_relationships)
        
        # 6. 使用大模型生成回答
        print("正在使用大模型生成回答...")
        start_llm = time.time()
        answer = self.generate_response_with_llm(
            question=question,
            entities=entities,
            entity_info=all_entity_info,
            relationships=all_relationships,
            paths=all_paths
        )
        llm_time = time.time() - start_llm
        print(f"大模型回答生成完成，耗时: {llm_time:.2f}秒")
        
        # 7. 构建知识图谱可视化数据
        print("正在构建可视化数据...")
        kg_data = self._convert_to_visual_data(all_entity_info, original_relationships, all_paths)
        
        # 8. 格式化关系数据为三元组格式
        context = self._format_relations_for_context(original_relationships, inferred_relationships)
        
        # 计算总处理时间
        total_time = time.time() - start_time
        print(f"问题处理完成，总耗时: {total_time:.2f}秒")
        
        # 返回结果，包括回答内容、实体列表、知识图谱数据和上下文信息
        return {
            'answer': answer,
            'entities': entities,
            'kg_data': kg_data,
            'context': context,
            'process_time': total_time
        }
            
    except Exception as e:
        error_time = time.time() - start_time
        print(f"处理问题出错: {str(e)}, 耗时: {error_time:.2f}秒")
        import traceback
        error_details = traceback.format_exc()
        print(f"错误详情: {error_details}")
        
        return {
            'answer': f"抱歉，在处理您的问题时遇到了错误: {str(e)}",
            'entities': [],
            'kg_data': {'nodes': [], 'lines': []},
            'error': str(e),
            'error_details': error_details,
            'process_time': error_time
        }
```

### 7.2 可视化数据转换

系统将实体和关系转换为前端可视化所需的格式，前端使用ECharts等工具进行图谱可视化：

```python
def _convert_to_visual_data(self, entities, relationships, paths):
    """将实体、关系和路径转换为可视化数据格式"""
    nodes = []
    lines = []
    
    # 实体ID到索引的映射
    entity_id_to_index = {}
    
    # 处理实体节点
    for i, entity in enumerate(entities):
        entity_id = entity.get('id')
        if entity_id:
            entity_id_to_index[entity_id] = i
            
        nodes.append({
            'id': entity_id,
            'name': entity.get('name', '未知实体'),
            'type': entity.get('type', '未知类型'),
            'properties': entity.get('properties', {})
        })
    
    # 处理关系线条
    for rel in relationships:
        source_id = rel.get('source', {}).get('id')
        target_id = rel.get('target', {}).get('id')
        
        if source_id in entity_id_to_index and target_id in entity_id_to_index:
            lines.append({
                'source': entity_id_to_index[source_id],
                'target': entity_id_to_index[target_id],
                'relation': rel.get('relation', ''),
                'properties': rel.get('properties', {}),
                'inferred': rel.get('properties', {}).get('inferred', False)
            })
    
    return {
        'nodes': nodes,
        'lines': lines
    }
```

### 7.3 前后端交互

系统通过RESTful API实现前后端交互，前端使用Vue框架开发，后端使用Flask提供API服务。

#### 7.3.1 后端API实现

后端提供了`/api/ai/inference`端点处理推理请求：

```python
@app.route('/api/ai/inference', methods=['POST', 'GET'])
def ai_inference():
    """
    人工智能推理接口
    使用规则引擎和大模型进行推理
    """
    try:
        # 获取请求数据
        if request.method == 'POST':
            data = request.json
            user_question = data.get('question', '')
        else:  # GET方法
            user_question = request.args.get('question', '')
        
        if not user_question:
            return jsonify({
                'code': 400,
                'message': '请提供问题内容',
                'data': None
            })
            
        # 记录请求信息
        print(f"收到AI推理请求: {user_question}")
        
        # 调用规则和模型进行推理
        result = g.rule_llm_integration.process_question(
            question=user_question,
            entity_extractor=g.entity_extractor,
            neo4j_db=neo4j_db_handle
        )
        
        # 返回结果
        return jsonify({
            'code': 200,
            'message': 'success',
            'data': result
        })
        
    except Exception as e:
        print(f"AI推理处理错误: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            'code': 500,
            'message': f'服务器处理错误: {str(e)}',
            'data': None
        })
```

#### 7.3.2 前端实现

前端通过HTTP请求与后端交互，发送用户问题并处理结果，主要使用Vue框架开发。前端核心组件位于`place-name-kg-frontend/src/views/inference/index.vue`，实现了对话界面、知识图谱可视化等功能。

前端HTTP请求封装：

```typescript
// http.ts
import axios from 'axios';

class Http {
    service;

    constructor(config) {
        this.service = axios.create(config)

        /* 请求拦截 */
        this.service.interceptors.request.use((config) => {
            const userInfoStore = useUserStore();
            if (userInfoStore.token) {
                config.headers.token = userInfoStore.token
            } else {
                if (router.currentRoute.value.path !== '/login') {
                    router.push('/login');
                }
            }
            return config
        }, error => {
            return Promise.reject(error);
        })

        /* 响应拦截 */
        this.service.interceptors.response.use((response) => {
            console.log('API响应原始数据:', response.data)
            
            // 统一返回数据，不执行其他操作
            return response.data;
            
        }, error => {
            console.error('API请求错误:', error);
            return Promise.reject(error)
        })
    }

    /* POST 方法 */
    post(url, params, _object = {}) {
        return this.service.post(url, params, _object)
    }
}

export default new Http(axiosConfig)
```

推理请求发送：

```javascript
// 在inference/index.vue中

// 发送问题
async sendMessage() {
  if (!this.userInput.trim()) return;
  
  // 保存用户输入并清空输入框
  const userQuestion = this.userInput.trim();
  this.userInput = '';
  
  // 添加到对话记录
  this.currentChat.messages.push({
    role: 'user',
    content: userQuestion,
    time: Date.now()
  });
  
  // 更新聊天标题（如果是第一条消息）
  if (this.currentChat.title === '新对话' && this.currentChat.messages.length === 1) {
    this.currentChat.title = userQuestion.length > 20 
      ? userQuestion.substring(0, 20) + '...' 
      : userQuestion;
  }
  
  // 滚动到底部
  this.scrollToBottom();
  
  // 设置加载状态
  this.loading = true;
  
  try {
    // 发送API请求
    const response = await http.post('/api/ai/inference', {
      question: userQuestion
    });
    
    // 处理响应
    if (response.code === 200) {
      // 添加AI回复到聊天记录
      this.currentChat.messages.push({
        role: 'assistant',
        content: response.data.answer,
        time: Date.now(),
        entities: response.data.entities || [],
        kgContext: response.data.context || '',
        kgData: response.data.kg_data || {nodes: [], lines: []},
        fromKg: response.data.entities && response.data.entities.length > 0
      });
      
      // 保存聊天记录
      this.saveChat();
    } else {
      // 处理错误响应
      this.currentChat.messages.push({
        role: 'assistant',
        content: `抱歉，我遇到了问题: ${response.message || '未知错误'}`,
        time: Date.now()
      });
    }
  } catch (error) {
    // 处理异常
    console.error('发送消息出错:', error);
    this.currentChat.messages.push({
      role: 'assistant',
      content: `抱歉，发生了错误: ${error.message || '连接服务器失败'}`,
      time: Date.now()
    });
  } finally {
    // 关闭加载状态
    this.loading = false;
    // 滚动到底部
    this.$nextTick(() => this.scrollToBottom());
  }
}
```

#### 7.3.3 知识图谱可视化实现

前端通过使用图形库（如ECharts）实现知识图谱可视化：

```vue
<template>
  <!-- 知识图谱可视化 -->
  <div v-if="message.role === 'assistant' && message.kgContext" class="kg-visualization" @click.stop>
    <div class="kg-header" @click.stop="toggleKgVisualization(msgIndex, $event)">
      <lay-icon :type="showKgVisualization[msgIndex] ? 'layui-icon-up' : 'layui-icon-down'" color="#009688"></lay-icon>
      <span>{{ showKgVisualization[msgIndex] ? '隐藏知识图谱' : '显示知识图谱' }}</span>
    </div>
    
    <div v-if="showKgVisualization[msgIndex]" class="kg-graph-wrapper" @click.stop @mousedown.stop @touchstart.stop>
      <div class="kg-graph-container" @click.stop @mousedown.stop @touchstart.stop>
        <div v-if="getKgData(message).nodes.length === 0" class="kg-empty" @click.stop>
          <lay-icon type="layui-icon-about" color="#FF9800"></lay-icon>
          <span>没有检索到相关的知识图谱数据</span>
        </div>
        <kg-graph v-else :data="getKgData(message)" class="kg-graph"></kg-graph>
      </div>
    </div>
  </div>
</template>

<script>
export default {
  methods: {
    getKgData(message) {
      return message.kgData || { nodes: [], lines: [] };
    },
    toggleKgVisualization(index, event) {
      // 防止事件冒泡
      if (event) {
        event.stopPropagation();
      }
      // 切换可视化显示状态
      this.$set(this.showKgVisualization, index, !this.showKgVisualization[index]);
    }
  }
}
</script>
```

### 7.4 系统调用流程

整个系统的调用流程如下：

1. 用户在前端输入问题，点击发送
2. 前端将问题发送到后端的`/api/ai/inference`端点
3. 后端接收请求并调用`process_question`方法进行处理
4. 系统使用大模型抽取问题中的地名实体
5. 根据抽取的实体从知识图谱中查询相关信息
6. 应用规则推理生成隐含的关系
7. 将所有信息提供给大模型，生成最终回答
8. 后端将回答、实体列表、图谱数据等信息返回给前端
9. 前端接收结果，展示回答内容，并提供知识图谱可视化
10. 用户可以查看回答内容，以及相关的知识图谱和引用信息

## 总结

规则引擎与大模型推理系统是本项目的核心组件，实现了基于知识图谱的混合推理能力。系统通过规则定义和应用实现了符号推理，通过大模型集成实现了神经推理，两者相互补充，共同提升了地名知识问答的准确性和专业性。

系统的主要优势包括：
1. 通过规则推理扩展了知识图谱的覆盖范围
2. 通过大模型提升了自然语言理解和生成能力
3. 通过提示词工程引导模型进行专业化推理
4. 明确区分原始关系和推理关系，保证推理过程透明可解释
5. 良好的前后端交互体验和知识图谱可视化能力

这种混合推理方法为地名知识图谱的智能问答提供了强大的技术支持，具有很好的扩展性和适用性。通过持续优化规则库和提示词设计，系统的推理能力可以进一步提升。 